{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Input"
      ],
      "metadata": {
        "id": "JBJovcKmBSBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYRF7TZswo5e",
        "outputId": "dc9e0d60-ee1f-4e63-c12a-0a1e989d6aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# Read train and dev data\n",
        "train = pd.read_csv('/content/drive/MyDrive/sem/Copy of tam_sentiment_train.tsv', sep='\\t')\n",
        "dev = pd.read_csv('/content/drive/MyDrive/sem/tam_sentiment_dev.tsv', sep='\\t')\n",
        "\n",
        "# Text vectorization using CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3), lowercase=True)\n",
        "\n",
        "X_train = vectorizer.fit_transform(train['text'])\n",
        "X_dev = vectorizer.transform(dev['text'])\n",
        "\n",
        "# Target labels\n",
        "y_train = train['category']\n",
        "y_actual1 = dev['category']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running All Classifiers"
      ],
      "metadata": {
        "id": "2Rbjy13vBITh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwFbU44SmCNd"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "clf_random_forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "clf_random_forest.fit(X_train, y_train)\n",
        "y_pred_random_forest = clf_random_forest.predict(X_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw-C2_B4l-zx"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "clf_decision_tree = DecisionTreeClassifier()\n",
        "clf_decision_tree.fit(X_train, y_train)\n",
        "y_pred_decision_tree = clf_decision_tree.predict(X_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieSg6c8Ul9ID"
      },
      "outputs": [],
      "source": [
        "# MLP\n",
        "clf_mlp = MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=100)\n",
        "clf_mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = clf_mlp.predict(X_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcou7MtYmEmE"
      },
      "outputs": [],
      "source": [
        "# SVM\n",
        "clf_svm = SVC(kernel='linear', C=0.05)\n",
        "clf_svm.fit(X_train, y_train)\n",
        "y_pred_svm = clf_svm.predict(X_dev)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0zOHNPJotbE"
      },
      "outputs": [],
      "source": [
        "# Extra Trees\n",
        "clf_extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
        "clf_extra_trees.fit(X_train, y_train)\n",
        "y_pred_extra_trees = clf_extra_trees.predict(X_dev)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "clf_logistic_regression = LogisticRegression(max_iter=100)  # Increase max_iter if needed\n",
        "clf_logistic_regression.fit(X_train, y_train)\n",
        "y_pred_logistic_regression = clf_logistic_regression.predict(X_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA_E6YwbDrGp",
        "outputId": "4f8b76bd-24ba-497b-8a4c-4a9a1615a351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results of Single Classifiers"
      ],
      "metadata": {
        "id": "kWDYw8HsBLq7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7m4OeRZoxvy"
      },
      "outputs": [],
      "source": [
        "mapping = {\n",
        "    4: \"Positive\",\n",
        "    3: \"Negative\",\n",
        "    2: \"Mixed_feelings\",\n",
        "    1: \"unknown_state\",\n",
        "    0: \"not-Tamil\",\n",
        "    # Add more mappings if needed...\n",
        "}\n",
        "\n",
        "# Define a custom mapping to decode the labels\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vfRofgIo2XN",
        "outputId": "3d2f4ddb-29bc-4ac2-cdc2-be4ae5390c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extra Trees Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.47      0.11      0.17       438\n",
            "      Negative       0.58      0.09      0.15       480\n",
            "      Positive       0.62      0.97      0.76      2257\n",
            "     not-Tamil       0.84      0.40      0.54       176\n",
            " unknown_state       0.66      0.21      0.31       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.63      0.35      0.39      3962\n",
            "  weighted avg       0.61      0.62      0.54      3962\n",
            "\n",
            "[[  46    5  372    1   14]\n",
            " [   7   42  412    5   14]\n",
            " [  21   14 2181    5   36]\n",
            " [   0    2  102   70    2]\n",
            " [  24    9  450    2  126]]\n",
            "Accuracy: 0.6221605249873801\n",
            "\n",
            "MLP Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.27      0.20      0.23       438\n",
            "      Negative       0.41      0.34      0.37       480\n",
            "      Positive       0.71      0.78      0.74      2257\n",
            "     not-Tamil       0.58      0.58      0.58       176\n",
            " unknown_state       0.43      0.42      0.42       611\n",
            "\n",
            "      accuracy                           0.60      3962\n",
            "     macro avg       0.48      0.46      0.47      3962\n",
            "  weighted avg       0.58      0.60      0.59      3962\n",
            "\n",
            "[[  86   56  226    8   62]\n",
            " [  46  164  195   14   61]\n",
            " [ 129  138 1760   41  189]\n",
            " [   9    3   40  102   22]\n",
            " [  51   43  252   11  254]]\n",
            "Accuracy: 0.5971731448763251\n",
            "\n",
            "Decision Tree Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.20      0.18      0.19       438\n",
            "      Negative       0.24      0.23      0.23       480\n",
            "      Positive       0.68      0.70      0.69      2257\n",
            "     not-Tamil       0.39      0.36      0.38       176\n",
            " unknown_state       0.33      0.32      0.32       611\n",
            "\n",
            "      accuracy                           0.51      3962\n",
            "     macro avg       0.37      0.36      0.36      3962\n",
            "  weighted avg       0.51      0.51      0.51      3962\n",
            "\n",
            "[[  80   78  195   10   75]\n",
            " [  60  109  229   18   64]\n",
            " [ 184  192 1589   54  238]\n",
            " [  12   12   60   64   28]\n",
            " [  61   71  266   17  196]]\n",
            "Accuracy: 0.5143866733972741\n",
            "\n",
            "Random Forest Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.45      0.10      0.16       438\n",
            "      Negative       0.57      0.06      0.12       480\n",
            "      Positive       0.62      0.97      0.75      2257\n",
            "     not-Tamil       0.84      0.31      0.45       176\n",
            " unknown_state       0.69      0.20      0.31       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.64      0.33      0.36      3962\n",
            "  weighted avg       0.61      0.62      0.53      3962\n",
            "\n",
            "[[  43    5  371    1   18]\n",
            " [   9   31  429    3    8]\n",
            " [  19   11 2199    4   24]\n",
            " [   1    0  117   54    4]\n",
            " [  24    7  455    2  123]]\n",
            "Accuracy: 0.6183745583038869\n",
            "\n",
            "SVM Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.28      0.16      0.20       438\n",
            "      Negative       0.46      0.33      0.38       480\n",
            "      Positive       0.70      0.87      0.78      2257\n",
            "     not-Tamil       0.71      0.53      0.61       176\n",
            " unknown_state       0.48      0.35      0.40       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.53      0.45      0.47      3962\n",
            "  weighted avg       0.59      0.63      0.60      3962\n",
            "\n",
            "[[  69   56  260    5   48]\n",
            " [  45  157  231    7   40]\n",
            " [  74   85 1962   13  123]\n",
            " [   4    2   61   94   15]\n",
            " [  56   41  288   14  212]]\n",
            "Accuracy: 0.6294800605754669\n",
            "\\Logistic Regression Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.31      0.14      0.19       438\n",
            "      Negative       0.49      0.31      0.38       480\n",
            "      Positive       0.69      0.88      0.77      2257\n",
            "     not-Tamil       0.70      0.47      0.56       176\n",
            " unknown_state       0.46      0.34      0.39       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.53      0.43      0.46      3962\n",
            "  weighted avg       0.59      0.63      0.59      3962\n",
            "\n",
            "[[  62   42  268    5   61]\n",
            " [  30  148  246    8   48]\n",
            " [  67   73 1982   14  121]\n",
            " [   2    1   75   83   15]\n",
            " [  37   39  316    9  210]]\n",
            "Accuracy: 0.627208480565371\n"
          ]
        }
      ],
      "source": [
        "# Classification reports for individual models\n",
        "print(\"\\nExtra Trees Classification Report:\")\n",
        "print(classification_report(y_actual1, y_pred_extra_trees))\n",
        "print(confusion_matrix(y_actual1, y_pred_extra_trees))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,y_pred_extra_trees ))\n",
        "\n",
        "print(\"\\nMLP Classification Report:\")\n",
        "print(classification_report(y_actual1, y_pred_mlp))\n",
        "print(confusion_matrix(y_actual1, y_pred_mlp))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,y_pred_mlp ))\n",
        "\n",
        "print(\"\\nDecision Tree Classification Report:\")\n",
        "print(classification_report(y_actual1, y_pred_decision_tree))\n",
        "print(confusion_matrix(y_actual1, y_pred_decision_tree))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,y_pred_decision_tree ))\n",
        "\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(classification_report(y_actual1, y_pred_random_forest))\n",
        "print(confusion_matrix(y_actual1, y_pred_random_forest))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,y_pred_random_forest ))\n",
        "\n",
        "print(\"\\nSVM Classification Report:\")\n",
        "print(classification_report(y_actual1, y_pred_svm))\n",
        "print(confusion_matrix(y_actual1, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,y_pred_svm ))\n",
        "\n",
        "print(\"\\Logistic Regression Report:\")\n",
        "print(classification_report(y_actual1, y_pred_logistic_regression))\n",
        "print(confusion_matrix(y_actual1, y_pred_logistic_regression))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,y_pred_logistic_regression ))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddG7KkgWNRR"
      },
      "outputs": [],
      "source": [
        "mapping = {\n",
        "    \"Positive\": 4,\n",
        "    \"Negative\": 3,\n",
        "    \"Mixed_feelings\": 2,\n",
        "    \"unknown_state\":1,\n",
        "    \"not-Tamil\":0,\n",
        "    \"Positive \":4\n",
        "}\n",
        "\n",
        "\n",
        "# Define a custom mapping to decode the labels\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "\n",
        "#y_pred_extra_trees, y_pred_mlp, y_pred_decision_tree, y_pred_random_forest, y_pred_svm\n",
        "# Encode the labels\n",
        "y_pred_extra_trees = [mapping[label] for label in y_pred_extra_trees]\n",
        "y_pred_mlp = [mapping[label] for label in y_pred_mlp]\n",
        "y_pred_decision_tree=  [mapping[label] for label in y_pred_decision_tree]\n",
        "y_pred_random_forest=  [mapping[label] for label in y_pred_random_forest]\n",
        "y_pred_svm=  [mapping[label] for label in y_pred_svm]\n",
        "y_pred_logistic_regression=  [mapping[label] for label in y_pred_logistic_regression]\n",
        "\n",
        "\n",
        "mapping = {\n",
        "    \"Positive\": 4,\n",
        "    \"Negative\": 3,\n",
        "    \"Mixed_feelings\": 2,\n",
        "    \"unknown_state\":1,\n",
        "    \"not-Tamil\":0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IgWbX1gWm1P",
        "outputId": "3cf2de85-d095-48b6-94f4-92f8cfcfc57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.39      0.14      0.21       438\n",
            "      Negative       0.51      0.22      0.31       480\n",
            "      Positive       0.67      0.92      0.77      2257\n",
            "     not-Tamil       0.80      0.49      0.61       176\n",
            " unknown_state       0.55      0.33      0.41       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.58      0.42      0.46      3962\n",
            "  weighted avg       0.60      0.64      0.59      3962\n",
            "\n",
            "[[  61   32  304    2   39]\n",
            " [  21  107  314    5   33]\n",
            " [  41   46 2077    8   85]\n",
            " [   1    0   78   86   11]\n",
            " [  33   24  345    7  202]]\n",
            "Accuracy: 0.6393235739525492\n"
          ]
        }
      ],
      "source": [
        "predictions = np.array([y_pred_extra_trees, y_pred_mlp, y_pred_decision_tree, y_pred_random_forest, y_pred_svm,y_pred_logistic_regression]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#<font color='yellow'>***Results with FUSION***</font>"
      ],
      "metadata": {
        "id": "NunlpjQREEGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting with ExtraTrees"
      ],
      "metadata": {
        "id": "fvvm0gu3Bdm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_extra_trees, y_pred_mlp]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FNzndI0A-_l",
        "outputId": "35e107e4-dfe8-4151-846b-7ab28bb41408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.28      0.21      0.24       438\n",
            "      Negative       0.41      0.34      0.37       480\n",
            "      Positive       0.72      0.77      0.74      2257\n",
            "     not-Tamil       0.59      0.61      0.60       176\n",
            " unknown_state       0.43      0.44      0.44       611\n",
            "\n",
            "      accuracy                           0.60      3962\n",
            "     macro avg       0.49      0.48      0.48      3962\n",
            "  weighted avg       0.58      0.60      0.59      3962\n",
            "\n",
            "[[  94   56  213    8   67]\n",
            " [  46  163  191   15   65]\n",
            " [ 132  139 1741   42  203]\n",
            " [   9    3   37  108   19]\n",
            " [  53   36  241   11  270]]\n",
            "Accuracy: 0.5996971226653205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_extra_trees, y_pred_decision_tree]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfhCw3j1BvlX",
        "outputId": "03a96826-8ee3-4fda-e7d2-08422a5a8fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.23      0.21      0.22       438\n",
            "      Negative       0.25      0.24      0.25       480\n",
            "      Positive       0.70      0.70      0.70      2257\n",
            "     not-Tamil       0.46      0.49      0.48       176\n",
            " unknown_state       0.35      0.37      0.36       611\n",
            "\n",
            "      accuracy                           0.53      3962\n",
            "     macro avg       0.40      0.40      0.40      3962\n",
            "  weighted avg       0.53      0.53      0.53      3962\n",
            "\n",
            "[[  93   70  184   10   81]\n",
            " [  58  115  215   20   72]\n",
            " [ 188  189 1574   55  251]\n",
            " [  10   10   48   87   21]\n",
            " [  63   68  236   17  227]]\n",
            "Accuracy: 0.5290257445734478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_extra_trees, y_pred_random_forest]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKKBdTI4Bzqr",
        "outputId": "5f2c473c-0047-401e-bc82-f6d01459083f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.46      0.12      0.19       438\n",
            "      Negative       0.58      0.10      0.17       480\n",
            "      Positive       0.63      0.96      0.76      2257\n",
            "     not-Tamil       0.85      0.41      0.55       176\n",
            " unknown_state       0.65      0.25      0.36       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.63      0.37      0.41      3962\n",
            "  weighted avg       0.62      0.63      0.55      3962\n",
            "\n",
            "[[  52    7  357    1   21]\n",
            " [  11   49  401    5   14]\n",
            " [  25   18 2168    5   41]\n",
            " [   1    1   97   72    5]\n",
            " [  25   10  424    2  150]]\n",
            "Accuracy: 0.6287228672387682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_extra_trees, y_pred_svm]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG-jSN5hB2hB",
        "outputId": "5af0630c-f768-40bc-cfb9-828259af5764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.30      0.19      0.23       438\n",
            "      Negative       0.47      0.32      0.38       480\n",
            "      Positive       0.71      0.86      0.78      2257\n",
            "     not-Tamil       0.71      0.55      0.62       176\n",
            " unknown_state       0.49      0.39      0.43       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.53      0.46      0.49      3962\n",
            "  weighted avg       0.60      0.63      0.61      3962\n",
            "\n",
            "[[  82   49  250    5   52]\n",
            " [  47  153  225    7   48]\n",
            " [  82   87 1936   14  138]\n",
            " [   3    2   59   96   16]\n",
            " [  57   38  262   14  240]]\n",
            "Accuracy: 0.632761231701161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_extra_trees, y_pred_logistic_regression]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p26A1uXWB5jZ",
        "outputId": "408154e3-fc4e-41ca-c8a5-8b483bc80762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.33      0.17      0.22       438\n",
            "      Negative       0.49      0.31      0.38       480\n",
            "      Positive       0.70      0.87      0.77      2257\n",
            "     not-Tamil       0.70      0.51      0.59       176\n",
            " unknown_state       0.48      0.40      0.44       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.54      0.45      0.48      3962\n",
            "  weighted avg       0.60      0.63      0.60      3962\n",
            "\n",
            "[[  74   38  255    5   66]\n",
            " [  31  147  240    8   54]\n",
            " [  76   77 1953   17  134]\n",
            " [   2    1   68   90   15]\n",
            " [  38   35  283    9  246]]\n",
            "Accuracy: 0.6335184250378597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting with MLP"
      ],
      "metadata": {
        "id": "tbYHbpchCBDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_mlp, y_pred_decision_tree]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnIYiDaoCEP7",
        "outputId": "d5bc137a-cfa8-43e1-b07a-a258c0a4eed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.23      0.27      0.25       438\n",
            "      Negative       0.30      0.31      0.30       480\n",
            "      Positive       0.77      0.60      0.68      2257\n",
            "     not-Tamil       0.42      0.65      0.51       176\n",
            " unknown_state       0.34      0.52      0.41       611\n",
            "\n",
            "      accuracy                           0.52      3962\n",
            "     macro avg       0.41      0.47      0.43      3962\n",
            "  weighted avg       0.57      0.52      0.54      3962\n",
            "\n",
            "[[ 117   72  120   14  115]\n",
            " [  81  148  115   29  107]\n",
            " [ 235  208 1362   91  361]\n",
            " [   9    5   23  114   25]\n",
            " [  75   58  139   23  316]]\n",
            "Accuracy: 0.5191822311963654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_mlp, y_pred_random_forest]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycv5bCYDCKsQ",
        "outputId": "01e0456e-4c8a-495c-a42b-069bad74b9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.27      0.21      0.23       438\n",
            "      Negative       0.42      0.34      0.37       480\n",
            "      Positive       0.72      0.77      0.75      2257\n",
            "     not-Tamil       0.59      0.61      0.60       176\n",
            " unknown_state       0.44      0.45      0.44       611\n",
            "\n",
            "      accuracy                           0.60      3962\n",
            "     macro avg       0.49      0.48      0.48      3962\n",
            "  weighted avg       0.58      0.60      0.59      3962\n",
            "\n",
            "[[  90   55  215    8   70]\n",
            " [  50  163  189   15   63]\n",
            " [ 134  139 1747   41  196]\n",
            " [   9    3   36  107   21]\n",
            " [  56   32  238   11  274]]\n",
            "Accuracy: 0.6009591115598183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_mlp, y_pred_svm]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuUI9hAjCNqV",
        "outputId": "40b7a2ab-4873-4a6f-dd45-db1fa4219db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.26      0.23      0.24       438\n",
            "      Negative       0.41      0.37      0.39       480\n",
            "      Positive       0.75      0.74      0.75      2257\n",
            "     not-Tamil       0.58      0.66      0.62       176\n",
            " unknown_state       0.42      0.51      0.46       611\n",
            "\n",
            "      accuracy                           0.60      3962\n",
            "     macro avg       0.48      0.50      0.49      3962\n",
            "  weighted avg       0.60      0.60      0.60      3962\n",
            "\n",
            "[[  99   64  182    9   84]\n",
            " [  72  176  145   15   72]\n",
            " [ 150  146 1666   45  250]\n",
            " [   6    4   30  117   19]\n",
            " [  57   39  189   17  309]]\n",
            "Accuracy: 0.5974255426552246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_mlp, y_pred_logistic_regression]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_PPCxFyCRgf",
        "outputId": "37692b16-2073-4810-edd1-6e77af27538b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.27      0.21      0.24       438\n",
            "      Negative       0.43      0.38      0.40       480\n",
            "      Positive       0.75      0.73      0.74      2257\n",
            "     not-Tamil       0.55      0.63      0.59       176\n",
            " unknown_state       0.41      0.53      0.46       611\n",
            "\n",
            "      accuracy                           0.60      3962\n",
            "     macro avg       0.48      0.50      0.49      3962\n",
            "  weighted avg       0.60      0.60      0.60      3962\n",
            "\n",
            "[[  94   56  177   11  100]\n",
            " [  54  183  143   17   83]\n",
            " [ 154  147 1656   49  251]\n",
            " [   5    2   35  111   23]\n",
            " [  41   41  194   14  321]]\n",
            "Accuracy: 0.5969207470974256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting with decision tree"
      ],
      "metadata": {
        "id": "QZ50B9EuCVZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_random_forest]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lniUgV9gCZjv",
        "outputId": "309f71fc-c3ab-425a-853d-686d7d781baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.21      0.20      0.21       438\n",
            "      Negative       0.25      0.23      0.24       480\n",
            "      Positive       0.69      0.70      0.70      2257\n",
            "     not-Tamil       0.42      0.43      0.42       176\n",
            " unknown_state       0.34      0.37      0.36       611\n",
            "\n",
            "      accuracy                           0.52      3962\n",
            "     macro avg       0.38      0.38      0.38      3962\n",
            "  weighted avg       0.52      0.52      0.52      3962\n",
            "\n",
            "[[  88   73  183   10   84]\n",
            " [  59  111  220   20   70]\n",
            " [ 187  191 1579   55  245]\n",
            " [  11   10   53   75   27]\n",
            " [  66   67  237   17  224]]\n",
            "Accuracy: 0.5242301867743564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_svm]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38B1juuVCc3W",
        "outputId": "e8571ddf-5d48-4103-e235-cdcdebae1f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.20      0.22      0.21       438\n",
            "      Negative       0.31      0.31      0.31       480\n",
            "      Positive       0.76      0.65      0.70      2257\n",
            "     not-Tamil       0.46      0.60      0.52       176\n",
            " unknown_state       0.35      0.48      0.41       611\n",
            "\n",
            "      accuracy                           0.53      3962\n",
            "     macro avg       0.42      0.45      0.43      3962\n",
            "  weighted avg       0.57      0.53      0.55      3962\n",
            "\n",
            "[[  96   72  150   13  107]\n",
            " [  79  149  134   22   96]\n",
            " [ 216  196 1469   63  313]\n",
            " [   5    5   32  105   29]\n",
            " [  76   58  155   26  296]]\n",
            "Accuracy: 0.5338213023725391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_logistic_regression]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PLy3oaFCfQS",
        "outputId": "9271ba0b-a09d-4454-ead4-7987f2b73c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.21      0.21      0.21       438\n",
            "      Negative       0.31      0.31      0.31       480\n",
            "      Positive       0.75      0.66      0.70      2257\n",
            "     not-Tamil       0.45      0.56      0.50       176\n",
            " unknown_state       0.36      0.49      0.41       611\n",
            "\n",
            "      accuracy                           0.54      3962\n",
            "     macro avg       0.42      0.45      0.43      3962\n",
            "  weighted avg       0.56      0.54      0.55      3962\n",
            "\n",
            "[[  92   73  147   13  113]\n",
            " [  71  148  144   22   95]\n",
            " [ 208  193 1487   64  305]\n",
            " [   5    5   40   99   27]\n",
            " [  62   60  167   22  300]]\n",
            "Accuracy: 0.5365976779404341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting with Random Forest"
      ],
      "metadata": {
        "id": "OmqGMKDgCrRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_random_forest, y_pred_svm]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW70C11LCvfk",
        "outputId": "d76142c2-d95f-4a1f-a25a-64e12fefc418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.28      0.17      0.22       438\n",
            "      Negative       0.47      0.32      0.38       480\n",
            "      Positive       0.71      0.86      0.78      2257\n",
            "     not-Tamil       0.71      0.55      0.62       176\n",
            " unknown_state       0.49      0.40      0.44       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.53      0.46      0.49      3962\n",
            "  weighted avg       0.60      0.63      0.61      3962\n",
            "\n",
            "[[  76   52  250    5   55]\n",
            " [  49  152  228    7   44]\n",
            " [  80   85 1943   13  136]\n",
            " [   4    1   59   96   16]\n",
            " [  59   35  257   14  246]]\n",
            "Accuracy: 0.6342756183745583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_random_forest, y_pred_logistic_regression]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIvdJHGtCy2o",
        "outputId": "4603d3cb-ceca-41cc-8530-f02cfc709cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.32      0.16      0.21       438\n",
            "      Negative       0.49      0.30      0.37       480\n",
            "      Positive       0.70      0.87      0.77      2257\n",
            "     not-Tamil       0.69      0.49      0.57       176\n",
            " unknown_state       0.48      0.40      0.44       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.54      0.44      0.47      3962\n",
            "  weighted avg       0.60      0.63      0.60      3962\n",
            "\n",
            "[[  70   39  258    5   66]\n",
            " [  34  143  243    8   52]\n",
            " [  71   77 1963   16  130]\n",
            " [   2    1   71   86   16]\n",
            " [  40   32  285    9  245]]\n",
            "Accuracy: 0.632761231701161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting with SVM"
      ],
      "metadata": {
        "id": "FIlFmFnuDA0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_logistic_regression]) # predictions of 2 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qquQGX4DDoy",
        "outputId": "8e37bdeb-f1ee-4792-bb96-0e69bfbb425d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.27      0.18      0.22       438\n",
            "      Negative       0.47      0.35      0.40       480\n",
            "      Positive       0.72      0.83      0.77      2257\n",
            "     not-Tamil       0.65      0.57      0.60       176\n",
            " unknown_state       0.44      0.43      0.44       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.51      0.47      0.49      3962\n",
            "  weighted avg       0.60      0.62      0.61      3962\n",
            "\n",
            "[[  78   49  226    8   77]\n",
            " [  55  167  187   10   61]\n",
            " [ 101   95 1869   21  171]\n",
            " [   3    1   55  100   17]\n",
            " [  49   42  243   16  261]]\n",
            "Accuracy: 0.6246845027763755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Majority Voting with 3 models"
      ],
      "metadata": {
        "id": "QFKyqKdYopV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_mlp,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "WEjT-fXxn_0b",
        "outputId": "262ac615-ae71-4e91-8e47-75134a93c641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.30      0.15      0.20       438\n",
            "      Negative       0.52      0.30      0.38       480\n",
            "      Positive       0.70      0.87      0.78      2257\n",
            "     not-Tamil       0.65      0.55      0.60       176\n",
            " unknown_state       0.45      0.37      0.41       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.52      0.45      0.47      3962\n",
            "  weighted avg       0.59      0.63      0.60      3962\n",
            "\n",
            "[[  67   42  261    6   62]\n",
            " [  45  146  223   11   55]\n",
            " [  65   60 1965   20  147]\n",
            " [   4    0   62   97   13]\n",
            " [  41   34  292   16  228]]\n",
            "Accuracy: 0.6317516405855629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,RF\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_random_forest,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "KA_uUjLzqEag",
        "outputId": "072c32d3-7df8-4402-c741-c82863d8c800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.34      0.13      0.19       438\n",
            "      Negative       0.53      0.24      0.33       480\n",
            "      Positive       0.68      0.91      0.78      2257\n",
            "     not-Tamil       0.76      0.50      0.60       176\n",
            " unknown_state       0.51      0.33      0.40       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.56      0.42      0.46      3962\n",
            "  weighted avg       0.60      0.64      0.59      3962\n",
            "\n",
            "[[  59   31  294    3   51]\n",
            " [  31  117  286    6   40]\n",
            " [  44   46 2063    9   95]\n",
            " [   2    0   77   88    9]\n",
            " [  36   27  335   10  203]]\n",
            "Accuracy: 0.6385663806158506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,DT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_decision_tree,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "DRslIIPfqRrB",
        "outputId": "bb3c0f90-21fb-4619-d8d1-675a509bd900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.34      0.17      0.22       438\n",
            "      Negative       0.50      0.28      0.36       480\n",
            "      Positive       0.70      0.87      0.78      2257\n",
            "     not-Tamil       0.60      0.53      0.56       176\n",
            " unknown_state       0.44      0.37      0.40       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.52      0.44      0.46      3962\n",
            "  weighted avg       0.59      0.63      0.60      3962\n",
            "\n",
            "[[  73   40  251    8   66]\n",
            " [  37  134  233   13   63]\n",
            " [  65   63 1965   25  139]\n",
            " [   2    0   65   93   16]\n",
            " [  38   32  299   15  227]]\n",
            "Accuracy: 0.6289752650176679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_extra_trees,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "vHWKZE1rqOYr",
        "outputId": "7994e5e1-5b20-4a65-c401-538a240d6f6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.35      0.14      0.20       438\n",
            "      Negative       0.53      0.24      0.33       480\n",
            "      Positive       0.68      0.91      0.78      2257\n",
            "     not-Tamil       0.77      0.53      0.63       176\n",
            " unknown_state       0.50      0.33      0.40       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.57      0.43      0.47      3962\n",
            "  weighted avg       0.60      0.64      0.60      3962\n",
            "\n",
            "[[  63   31  291    3   50]\n",
            " [  32  116  282    6   44]\n",
            " [  46   45 2060    9   97]\n",
            " [   1    1   72   93    9]\n",
            " [  38   26  334   10  203]]\n",
            "Accuracy: 0.6398283695103483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,RF,DT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_random_forest,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "GmGo16e2qisf",
        "outputId": "a0c1ecd5-b3ef-40ee-d447-c5494b133c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.36      0.14      0.20       438\n",
            "      Negative       0.50      0.14      0.21       480\n",
            "      Positive       0.66      0.91      0.77      2257\n",
            "     not-Tamil       0.59      0.41      0.49       176\n",
            " unknown_state       0.47      0.32      0.38       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.52      0.38      0.41      3962\n",
            "  weighted avg       0.57      0.62      0.56      3962\n",
            "\n",
            "[[  61   20  296    4   57]\n",
            " [  29   65  319   12   55]\n",
            " [  49   32 2061   21   94]\n",
            " [   2    0   86   73   15]\n",
            " [  29   13  361   13  195]]\n",
            "Accuracy: 0.6196365471983847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,RF,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_mlp,y_pred_random_forest,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "Q1DcjxCtqipE",
        "outputId": "edc8a003-def0-4874-fff2-c87b9dd3c687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.37      0.14      0.20       438\n",
            "      Negative       0.56      0.22      0.31       480\n",
            "      Positive       0.67      0.91      0.77      2257\n",
            "     not-Tamil       0.70      0.50      0.58       176\n",
            " unknown_state       0.51      0.35      0.42       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.56      0.42      0.46      3962\n",
            "  weighted avg       0.60      0.64      0.59      3962\n",
            "\n",
            "[[  61   22  302    3   50]\n",
            " [  27  104  289   10   50]\n",
            " [  48   40 2064   14   91]\n",
            " [   1    0   76   88   11]\n",
            " [  30   19  339   10  213]]\n",
            "Accuracy: 0.6385663806158506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,RF,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_random_forest, y_pred_extra_trees,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "vkkU8-C5qilK",
        "outputId": "d1a08fa6-1bbb-4cb3-9635-a7f33c4fc71c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.45      0.10      0.17       438\n",
            "      Negative       0.62      0.09      0.16       480\n",
            "      Positive       0.63      0.97      0.76      2257\n",
            "     not-Tamil       0.85      0.40      0.54       176\n",
            " unknown_state       0.66      0.23      0.34       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.64      0.36      0.39      3962\n",
            "  weighted avg       0.62      0.63      0.55      3962\n",
            "\n",
            "[[  45    6  364    1   22]\n",
            " [  13   43  404    5   15]\n",
            " [  20   12 2188    4   33]\n",
            " [   1    0  102   70    3]\n",
            " [  21    8  440    2  140]]\n",
            "Accuracy: 0.6274608783442706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,DT,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_mlp,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "DC_aKRzIqlb9",
        "outputId": "e08fd71d-9f13-4c2a-a28c-2f023fb3432a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.32      0.18      0.23       438\n",
            "      Negative       0.48      0.26      0.34       480\n",
            "      Positive       0.70      0.83      0.76      2257\n",
            "     not-Tamil       0.55      0.59      0.57       176\n",
            " unknown_state       0.41      0.42      0.42       611\n",
            "\n",
            "      accuracy                           0.61      3962\n",
            "     macro avg       0.49      0.45      0.46      3962\n",
            "  weighted avg       0.58      0.61      0.59      3962\n",
            "\n",
            "[[  77   39  234   10   78]\n",
            " [  42  126  218   17   77]\n",
            " [  85   68 1869   44  191]\n",
            " [   2    0   54  104   16]\n",
            " [  35   28  280   13  255]]\n",
            "Accuracy: 0.6135790005047955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,CT,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_extra_trees,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "6mdQCa2UqmNK",
        "outputId": "f47c1480-714d-45d0-dc6b-9d9cf3c24cdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.36      0.14      0.20       438\n",
            "      Negative       0.50      0.14      0.22       480\n",
            "      Positive       0.66      0.91      0.76      2257\n",
            "     not-Tamil       0.61      0.46      0.52       176\n",
            " unknown_state       0.46      0.31      0.37       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.52      0.39      0.41      3962\n",
            "  weighted avg       0.57      0.62      0.56      3962\n",
            "\n",
            "[[  60   20  298    4   56]\n",
            " [  29   68  315   13   55]\n",
            " [  49   33 2052   22  101]\n",
            " [   2    1   80   81   12]\n",
            " [  29   15  366   13  188]]\n",
            "Accuracy: 0.6181221605249874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_mlp, y_pred_extra_trees,y_pred_logistic_regression]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "mXx_Wy8eqnEm",
        "outputId": "c57ac802-f536-492e-866a-5b52e4d94cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 0 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.35      0.14      0.20       438\n",
            "      Negative       0.56      0.22      0.31       480\n",
            "      Positive       0.67      0.91      0.77      2257\n",
            "     not-Tamil       0.72      0.53      0.61       176\n",
            " unknown_state       0.50      0.35      0.41       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.56      0.43      0.46      3962\n",
            "  weighted avg       0.60      0.64      0.59      3962\n",
            "\n",
            "[[  60   24  301    3   50]\n",
            " [  25  105  288   10   52]\n",
            " [  53   40 2054   14   96]\n",
            " [   1    0   72   93   10]\n",
            " [  32   20  338   10  211]]\n",
            "Accuracy: 0.6367995961635537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,RF,DT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_decision_tree,y_pred_random_forest]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "2C6Lb4APqn1S",
        "outputId": "898998c8-63ed-4fcb-edf3-5b25d5a21aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.35      0.16      0.22       438\n",
            "      Negative       0.51      0.15      0.23       480\n",
            "      Positive       0.66      0.91      0.77      2257\n",
            "     not-Tamil       0.60      0.47      0.52       176\n",
            " unknown_state       0.49      0.32      0.38       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.52      0.40      0.42      3962\n",
            "  weighted avg       0.58      0.62      0.57      3962\n",
            "\n",
            "[[  68   23  289    6   52]\n",
            " [  33   70  314   15   48]\n",
            " [  54   31 2059   21   92]\n",
            " [   1    0   80   82   13]\n",
            " [  37   12  355   13  194]]\n",
            "Accuracy: 0.6241797072185765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,RF,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_random_forest,y_pred_mlp]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "eDBwot1gqomN",
        "outputId": "fd8559b1-d929-49f7-ce76-70ea7e9e8366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.32      0.14      0.19       438\n",
            "      Negative       0.54      0.23      0.32       480\n",
            "      Positive       0.68      0.90      0.78      2257\n",
            "     not-Tamil       0.70      0.53      0.60       176\n",
            " unknown_state       0.49      0.35      0.41       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.54      0.43      0.46      3962\n",
            "  weighted avg       0.59      0.64      0.59      3962\n",
            "\n",
            "[[  61   27  293    6   51]\n",
            " [  37  111  272    9   51]\n",
            " [  49   46 2040   13  109]\n",
            " [   3    0   69   94   10]\n",
            " [  42   22  322   13  212]]\n",
            "Accuracy: 0.6355376072690561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,RF,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_random_forest,y_pred_extra_trees]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "YpQ2iwxzr_X4",
        "outputId": "e1367b3c-7a0a-4317-fd8a-fe2bf0de6505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.44      0.10      0.17       438\n",
            "      Negative       0.59      0.09      0.16       480\n",
            "      Positive       0.63      0.97      0.76      2257\n",
            "     not-Tamil       0.86      0.41      0.56       176\n",
            " unknown_state       0.66      0.23      0.34       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.64      0.36      0.40      3962\n",
            "  weighted avg       0.62      0.63      0.55      3962\n",
            "\n",
            "[[  45    8  363    1   21]\n",
            " [  12   44  404    5   15]\n",
            " [  21   13 2187    4   32]\n",
            " [   0    1   99   73    3]\n",
            " [  24    9  437    2  139]]\n",
            "Accuracy: 0.6279656739020697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,DT,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_decision_tree,y_pred_mlp]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "4tcpGv73r_Ub",
        "outputId": "08f6792a-c7f1-453e-9d2e-3b1ded526881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.30      0.18      0.22       438\n",
            "      Negative       0.47      0.28      0.35       480\n",
            "      Positive       0.71      0.83      0.77      2257\n",
            "     not-Tamil       0.55      0.60      0.58       176\n",
            " unknown_state       0.42      0.41      0.41       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.49      0.46      0.47      3962\n",
            "  weighted avg       0.58      0.62      0.59      3962\n",
            "\n",
            "[[  79   45  234    8   72]\n",
            " [  54  132  206   17   71]\n",
            " [  83   71 1871   43  189]\n",
            " [   4    0   51  106   15]\n",
            " [  47   30  267   17  250]]\n",
            "Accuracy: 0.6153457849570924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,DT,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_decision_tree,y_pred_extra_trees]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "hpABrwGtr_R0",
        "outputId": "e62a42f9-01ef-404e-af4e-f9ff0cac3bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.36      0.16      0.22       438\n",
            "      Negative       0.52      0.15      0.24       480\n",
            "      Positive       0.67      0.91      0.77      2257\n",
            "     not-Tamil       0.60      0.49      0.54       176\n",
            " unknown_state       0.47      0.31      0.37       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.52      0.40      0.43      3962\n",
            "  weighted avg       0.58      0.62      0.57      3962\n",
            "\n",
            "[[  70   21  288    6   53]\n",
            " [  32   74  308   16   50]\n",
            " [  53   33 2049   22  100]\n",
            " [   0    2   75   87   12]\n",
            " [  38   13  359   13  188]]\n",
            "Accuracy: 0.6229177183240787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm, y_pred_extra_trees,y_pred_mlp]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "s47-ji0Sr_PU",
        "outputId": "96be6e14-5eb5-4497-e623-027dd1e4dff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.31      0.14      0.19       438\n",
            "      Negative       0.53      0.24      0.33       480\n",
            "      Positive       0.68      0.90      0.78      2257\n",
            "     not-Tamil       0.70      0.53      0.60       176\n",
            " unknown_state       0.48      0.34      0.39       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.54      0.43      0.46      3962\n",
            "  weighted avg       0.59      0.63      0.59      3962\n",
            "\n",
            "[[  62   29  289    6   52]\n",
            " [  36  113  271    9   51]\n",
            " [  55   45 2031   13  113]\n",
            " [   2    1   68   94   11]\n",
            " [  44   24  324   13  206]]\n",
            "Accuracy: 0.6325088339222615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF,DT,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_random_forest,y_pred_mlp]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "cCtU2vFHr_Ko",
        "outputId": "69f24e5a-69bb-42a6-9dd8-2077f6d8ed8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.31      0.16      0.21       438\n",
            "      Negative       0.50      0.15      0.23       480\n",
            "      Positive       0.66      0.87      0.75      2257\n",
            "     not-Tamil       0.54      0.51      0.52       176\n",
            " unknown_state       0.44      0.34      0.38       611\n",
            "\n",
            "      accuracy                           0.61      3962\n",
            "     macro avg       0.49      0.40      0.42      3962\n",
            "  weighted avg       0.57      0.61      0.56      3962\n",
            "\n",
            "[[  68   19  284    8   59]\n",
            " [  45   71  296   17   51]\n",
            " [  67   38 1972   39  141]\n",
            " [   3    0   70   89   14]\n",
            " [  33   14  346   12  206]]\n",
            "Accuracy: 0.607269056032307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF,DT,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_random_forest,y_pred_extra_trees]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "F12AXNVWr_Ct",
        "outputId": "aa82d84d-627a-4c24-e35b-3e815d927fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.45      0.10      0.16       438\n",
            "      Negative       0.52      0.07      0.12       480\n",
            "      Positive       0.62      0.97      0.76      2257\n",
            "     not-Tamil       0.81      0.38      0.51       176\n",
            " unknown_state       0.62      0.22      0.32       611\n",
            "\n",
            "      accuracy                           0.62      3962\n",
            "     macro avg       0.61      0.34      0.37      3962\n",
            "  weighted avg       0.60      0.62      0.54      3962\n",
            "\n",
            "[[  44    6  366    1   21]\n",
            " [   9   32  416    6   17]\n",
            " [  20   15 2179    5   38]\n",
            " [   1    1  104   66    4]\n",
            " [  23    8  445    3  132]]\n",
            "Accuracy: 0.6191317516405855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_extra_trees, y_pred_random_forest,y_pred_mlp]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "eAIjqxPlsFDd",
        "outputId": "c5329c76-77f2-4d6d-de10-da769dacf215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.42      0.10      0.16       438\n",
            "      Negative       0.66      0.08      0.15       480\n",
            "      Positive       0.62      0.97      0.76      2257\n",
            "     not-Tamil       0.85      0.41      0.55       176\n",
            " unknown_state       0.65      0.23      0.34       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.64      0.36      0.39      3962\n",
            "  weighted avg       0.62      0.63      0.55      3962\n",
            "\n",
            "[[  44    4  371    1   18]\n",
            " [   9   40  405    5   21]\n",
            " [  25   12 2184    4   32]\n",
            " [   2    0   98   72    4]\n",
            " [  24    5  437    3  142]]\n",
            "Accuracy: 0.6264512872286724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DT,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_decision_tree, y_pred_extra_trees,y_pred_mlp]) # predictions of 3 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "K7-yCPk-sF4G",
        "outputId": "085dbc6c-1036-4ae9-c978-b9a0490f5a89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.31      0.15      0.20       438\n",
            "      Negative       0.50      0.15      0.23       480\n",
            "      Positive       0.67      0.87      0.75      2257\n",
            "     not-Tamil       0.55      0.54      0.54       176\n",
            " unknown_state       0.43      0.34      0.38       611\n",
            "\n",
            "      accuracy                           0.61      3962\n",
            "     macro avg       0.49      0.41      0.42      3962\n",
            "  weighted avg       0.56      0.61      0.56      3962\n",
            "\n",
            "[[  65   21  283    8   61]\n",
            " [  40   73  293   18   56]\n",
            " [  71   39 1963   40  144]\n",
            " [   2    1   66   95   12]\n",
            " [  34   13  346   12  206]]\n",
            "Accuracy: 0.6062594649167087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Majority Voting with 4 models"
      ],
      "metadata": {
        "id": "1MPwd0vVvz7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,RF,DT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_svm,y_pred_random_forest,y_pred_decision_tree]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "gKVtTXCtv0gi",
        "outputId": "c31f5f99-2b78-410c-ee1b-f93179a1b8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.35      0.13      0.19       438\n",
            "      Negative       0.50      0.27      0.35       480\n",
            "      Positive       0.68      0.89      0.77      2257\n",
            "     not-Tamil       0.74      0.50      0.60       176\n",
            " unknown_state       0.49      0.36      0.42       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.55      0.43      0.47      3962\n",
            "  weighted avg       0.59      0.63      0.59      3962\n",
            "\n",
            "[[  59   41  280    3   55]\n",
            " [  26  131  274    6   43]\n",
            " [  52   63 2015   11  116]\n",
            " [   2    0   71   88   15]\n",
            " [  32   29  319   11  220]]\n",
            "Accuracy: 0.6342756183745583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,RF,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_svm,y_pred_random_forest,y_pred_mlp]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "6usZlwSYwiBF",
        "outputId": "7c54f1ba-06ba-4824-adae-99e4480d158a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.34      0.15      0.21       438\n",
            "      Negative       0.51      0.30      0.38       480\n",
            "      Positive       0.70      0.89      0.78      2257\n",
            "     not-Tamil       0.70      0.53      0.60       176\n",
            " unknown_state       0.51      0.39      0.44       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.55      0.45      0.48      3962\n",
            "  weighted avg       0.60      0.64      0.61      3962\n",
            "\n",
            "[[  66   42  273    4   53]\n",
            " [  29  144  252   10   45]\n",
            " [  54   62 2008   13  120]\n",
            " [   4    0   67   93   12]\n",
            " [  39   35  289   12  236]]\n",
            "Accuracy: 0.6428571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,RF,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_svm,y_pred_random_forest,y_pred_extra_trees]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "IBS4i6DuwqRC",
        "outputId": "a1884158-d74e-4a6b-e1ba-3db81d6de788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.37      0.13      0.19       438\n",
            "      Negative       0.52      0.24      0.33       480\n",
            "      Positive       0.67      0.92      0.77      2257\n",
            "     not-Tamil       0.80      0.49      0.61       176\n",
            " unknown_state       0.55      0.34      0.42       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.58      0.42      0.46      3962\n",
            "  weighted avg       0.60      0.64      0.59      3962\n",
            "\n",
            "[[  58   30  310    2   38]\n",
            " [  19  115  307    5   34]\n",
            " [  42   48 2071    8   88]\n",
            " [   2    0   79   86    9]\n",
            " [  36   27  335    7  206]]\n",
            "Accuracy: 0.6400807672892479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,DT,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_svm,y_pred_decision_tree,y_pred_mlp]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "LAJvhURCwyIh",
        "outputId": "e16580b8-f261-422b-e017-3f108ee97808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.32      0.16      0.22       438\n",
            "      Negative       0.48      0.34      0.40       480\n",
            "      Positive       0.71      0.84      0.77      2257\n",
            "     not-Tamil       0.66      0.55      0.60       176\n",
            " unknown_state       0.45      0.41      0.43       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.52      0.46      0.48      3962\n",
            "  weighted avg       0.60      0.63      0.60      3962\n",
            "\n",
            "[[  72   51  244    6   65]\n",
            " [  38  164  211   11   56]\n",
            " [  78   86 1906   17  170]\n",
            " [   3    0   58   96   19]\n",
            " [  37   42  265   15  252]]\n",
            "Accuracy: 0.6284704694598687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,DT,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_svm,y_pred_decision_tree,y_pred_extra_trees]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "rK90q4PAw_Vw",
        "outputId": "a453bc16-ec3a-4abb-81fb-8709332df39d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.36      0.15      0.21       438\n",
            "      Negative       0.50      0.28      0.35       480\n",
            "      Positive       0.68      0.89      0.77      2257\n",
            "     not-Tamil       0.74      0.52      0.61       176\n",
            " unknown_state       0.48      0.35      0.40       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.55      0.44      0.47      3962\n",
            "  weighted avg       0.59      0.63      0.59      3962\n",
            "\n",
            "[[  64   39  279    3   53]\n",
            " [  23  132  275    6   44]\n",
            " [  54   65 2007   12  119]\n",
            " [   2    0   68   91   15]\n",
            " [  34   30  323   11  213]]\n",
            "Accuracy: 0.632761231701161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_svm,y_pred_mlp,y_pred_extra_trees]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "gXUR4gprxGTf",
        "outputId": "cc695cb9-faef-4974-edd8-650f88bdcc64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.35      0.16      0.22       438\n",
            "      Negative       0.51      0.30      0.38       480\n",
            "      Positive       0.70      0.89      0.78      2257\n",
            "     not-Tamil       0.71      0.53      0.61       176\n",
            " unknown_state       0.50      0.38      0.43       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.55      0.45      0.48      3962\n",
            "  weighted avg       0.61      0.64      0.61      3962\n",
            "\n",
            "[[  69   41  272    4   52]\n",
            " [  28  146  249   10   47]\n",
            " [  56   63 2001   13  124]\n",
            " [   4    0   66   94   12]\n",
            " [  39   34  291   12  235]]\n",
            "Accuracy: 0.6423523472993438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,RF,DT,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_random_forest,y_pred_mlp,y_pred_decision_tree]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "kZuWlkmmxSGt",
        "outputId": "4dfafbe0-7280-4b33-c303-d88dd519f784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.36      0.14      0.20       438\n",
            "      Negative       0.48      0.26      0.34       480\n",
            "      Positive       0.68      0.88      0.77      2257\n",
            "     not-Tamil       0.71      0.51      0.59       176\n",
            " unknown_state       0.49      0.38      0.43       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.54      0.43      0.46      3962\n",
            "  weighted avg       0.59      0.63      0.59      3962\n",
            "\n",
            "[[  62   38  278    5   55]\n",
            " [  23  125  275    9   48]\n",
            " [  58   70 1986   13  130]\n",
            " [   2    0   72   89   13]\n",
            " [  29   29  312    9  232]]\n",
            "Accuracy: 0.6294800605754669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,RF,DT,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_random_forest,y_pred_extra_trees,y_pred_decision_tree]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "2LxYGL6lxfVU",
        "outputId": "c612443b-25e9-4ba6-ab1b-74745e1e7ec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.47      0.13      0.21       438\n",
            "      Negative       0.49      0.15      0.23       480\n",
            "      Positive       0.64      0.94      0.76      2257\n",
            "     not-Tamil       0.78      0.40      0.53       176\n",
            " unknown_state       0.55      0.27      0.36       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.59      0.38      0.42      3962\n",
            "  weighted avg       0.60      0.63      0.56      3962\n",
            "\n",
            "[[  58   20  326    2   32]\n",
            " [  11   72  366    6   25]\n",
            " [  29   37 2112    7   72]\n",
            " [   1    1   94   71    9]\n",
            " [  24   18  397    5  167]]\n",
            "Accuracy: 0.6259464916708734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,RF,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_random_forest,y_pred_extra_trees,y_pred_mlp]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "Wrpmh_qvxn73",
        "outputId": "8ce8c849-8b26-4336-fbbe-d36d49b6bf73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.40      0.13      0.19       438\n",
            "      Negative       0.55      0.22      0.32       480\n",
            "      Positive       0.66      0.93      0.77      2257\n",
            "     not-Tamil       0.79      0.48      0.60       176\n",
            " unknown_state       0.58      0.32      0.41       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.59      0.42      0.46      3962\n",
            "  weighted avg       0.61      0.64      0.59      3962\n",
            "\n",
            "[[  56   24  323    2   33]\n",
            " [  13  106  322    6   33]\n",
            " [  40   43 2092    8   74]\n",
            " [   1    0   84   85    6]\n",
            " [  31   19  356    7  198]]\n",
            "Accuracy: 0.6403331650681474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,DT,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_logistic_regression,y_pred_decision_tree,y_pred_extra_trees,y_pred_mlp]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "iu3H_eEYxytQ",
        "outputId": "db1a431d-30f4-4129-9dc1-9075771e2f34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.37      0.15      0.22       438\n",
            "      Negative       0.48      0.27      0.34       480\n",
            "      Positive       0.68      0.88      0.77      2257\n",
            "     not-Tamil       0.71      0.51      0.59       176\n",
            " unknown_state       0.48      0.38      0.42       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.54      0.44      0.47      3962\n",
            "  weighted avg       0.59      0.63      0.59      3962\n",
            "\n",
            "[[  67   36  278    5   52]\n",
            " [  21  128  273    9   49]\n",
            " [  63   71 1976   14  133]\n",
            " [   2    1   70   90   13]\n",
            " [  30   30  312    9  230]]\n",
            "Accuracy: 0.6287228672387682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,RF,DT,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_svm,y_pred_random_forest,y_pred_decision_tree,y_pred_mlp]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "5wdW4Xl8x-Rl",
        "outputId": "8499b161-f5a7-415f-fdc2-44eedd400942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.33      0.15      0.21       438\n",
            "      Negative       0.48      0.28      0.35       480\n",
            "      Positive       0.69      0.88      0.77      2257\n",
            "     not-Tamil       0.71      0.54      0.61       176\n",
            " unknown_state       0.49      0.37      0.42       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.54      0.44      0.47      3962\n",
            "  weighted avg       0.59      0.63      0.60      3962\n",
            "\n",
            "[[  66   45  271    6   50]\n",
            " [  32  133  261    9   45]\n",
            " [  61   71 1985   13  127]\n",
            " [   4    0   65   95   12]\n",
            " [  40   30  302   11  228]]\n",
            "Accuracy: 0.632761231701161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,RF,DT,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_svm,y_pred_random_forest,y_pred_decision_tree,y_pred_extra_trees]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "e7BaA1u2yOsN",
        "outputId": "414c489c-1d2d-4e7a-96b5-4107351ddcc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.41      0.12      0.18       438\n",
            "      Negative       0.51      0.16      0.25       480\n",
            "      Positive       0.64      0.94      0.76      2257\n",
            "     not-Tamil       0.80      0.44      0.57       176\n",
            " unknown_state       0.58      0.27      0.37       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.59      0.39      0.43      3962\n",
            "  weighted avg       0.60      0.63      0.57      3962\n",
            "\n",
            "[[  52   22  337    2   25]\n",
            " [  17   78  361    5   19]\n",
            " [  31   35 2116    6   69]\n",
            " [   1    1   90   77    7]\n",
            " [  25   17  396    6  167]]\n",
            "Accuracy: 0.6284704694598687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,RF,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_svm,y_pred_random_forest,y_pred_mlp,y_pred_extra_trees]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "XI06wFNqyVTz",
        "outputId": "47f86518-e298-4860-f761-f61156d919e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.37      0.13      0.20       438\n",
            "      Negative       0.53      0.24      0.33       480\n",
            "      Positive       0.67      0.92      0.77      2257\n",
            "     not-Tamil       0.75      0.49      0.60       176\n",
            " unknown_state       0.55      0.32      0.41       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.57      0.42      0.46      3962\n",
            "  weighted avg       0.60      0.64      0.59      3962\n",
            "\n",
            "[[  58   30  312    4   34]\n",
            " [  17  113  306    7   37]\n",
            " [  42   49 2074    9   83]\n",
            " [   3    0   77   87    9]\n",
            " [  36   22  346    9  198]]\n",
            "Accuracy: 0.6385663806158506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,DT,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_svm,y_pred_decision_tree,y_pred_mlp,y_pred_extra_trees]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "p4XZM4K8ynmC",
        "outputId": "4eea2708-b3ae-42d5-e168-e2daa89d5c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.34      0.16      0.22       438\n",
            "      Negative       0.49      0.29      0.36       480\n",
            "      Positive       0.69      0.88      0.77      2257\n",
            "     not-Tamil       0.70      0.54      0.61       176\n",
            " unknown_state       0.49      0.37      0.42       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.54      0.45      0.48      3962\n",
            "  weighted avg       0.60      0.63      0.60      3962\n",
            "\n",
            "[[  71   42  270    6   49]\n",
            " [  29  137  258    9   47]\n",
            " [  63   72 1978   14  130]\n",
            " [   4    1   64   95   12]\n",
            " [  39   30  305   11  226]]\n",
            "Accuracy: 0.632761231701161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF,DT,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([ y_pred_decision_tree,y_pred_random_forest,y_pred_mlp,y_pred_extra_trees]) # predictions of 4 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "0amyinmGyyG8",
        "outputId": "7d3ae0e3-2c03-4c96-d62a-2b3135743777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.40      0.12      0.19       438\n",
            "      Negative       0.50      0.16      0.25       480\n",
            "      Positive       0.64      0.93      0.76      2257\n",
            "     not-Tamil       0.79      0.44      0.56       176\n",
            " unknown_state       0.58      0.30      0.40       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.58      0.39      0.43      3962\n",
            "  weighted avg       0.60      0.63      0.57      3962\n",
            "\n",
            "[[  53   22  332    4   27]\n",
            " [  13   79  360    5   23]\n",
            " [  39   41 2096    6   75]\n",
            " [   2    1   88   77    8]\n",
            " [  25   16  380    5  185]]\n",
            "Accuracy: 0.6284704694598687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Majority Voting with 5 models"
      ],
      "metadata": {
        "id": "8SRYQL2uzq4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,RF,DT,MLP\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_logistic_regression,y_pred_svm, y_pred_decision_tree,y_pred_random_forest,y_pred_mlp,]) # predictions of 5 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "wcIBBJ70zuOE",
        "outputId": "f33ddf31-1831-4e62-bf06-104b887c2a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.37      0.16      0.22       438\n",
            "      Negative       0.50      0.28      0.36       480\n",
            "      Positive       0.69      0.90      0.78      2257\n",
            "     not-Tamil       0.72      0.52      0.60       176\n",
            " unknown_state       0.50      0.34      0.40       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.55      0.44      0.47      3962\n",
            "  weighted avg       0.60      0.64      0.60      3962\n",
            "\n",
            "[[  69   44  274    5   46]\n",
            " [  32  134  265    7   42]\n",
            " [  45   59 2036   12  105]\n",
            " [   3    0   66   91   16]\n",
            " [  39   33  323   11  205]]\n",
            "Accuracy: 0.6398283695103483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,RF,DT,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_logistic_regression,y_pred_svm, y_pred_decision_tree,y_pred_random_forest,y_pred_extra_trees,]) # predictions of 5 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "VBz4TdJx0k1L",
        "outputId": "2bc3f07f-d076-4c88-f7c9-b4786bdd30d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.39      0.12      0.18       438\n",
            "      Negative       0.49      0.19      0.28       480\n",
            "      Positive       0.65      0.94      0.77      2257\n",
            "     not-Tamil       0.79      0.46      0.58       176\n",
            " unknown_state       0.55      0.27      0.36       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.58      0.40      0.43      3962\n",
            "  weighted avg       0.59      0.63      0.57      3962\n",
            "\n",
            "[[  51   30  319    2   36]\n",
            " [  16   93  336    5   30]\n",
            " [  34   40 2114    7   62]\n",
            " [   2    0   83   81   10]\n",
            " [  29   25  383    7  167]]\n",
            "Accuracy: 0.6325088339222615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,RF,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_logistic_regression,y_pred_svm, y_pred_mlp,y_pred_random_forest,y_pred_extra_trees,]) # predictions of 5 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "eTjqsxU70vW3",
        "outputId": "f96f71df-bac2-4c0e-9ad3-1ff808b5e4f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.38      0.14      0.20       438\n",
            "      Negative       0.52      0.23      0.32       480\n",
            "      Positive       0.67      0.93      0.78      2257\n",
            "     not-Tamil       0.81      0.51      0.62       176\n",
            " unknown_state       0.56      0.31      0.40       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.59      0.42      0.46      3962\n",
            "  weighted avg       0.61      0.64      0.59      3962\n",
            "\n",
            "[[  61   28  313    2   34]\n",
            " [  21  110  311    5   33]\n",
            " [  37   45 2097    7   71]\n",
            " [   3    0   76   89    8]\n",
            " [  38   28  350    7  188]]\n",
            "Accuracy: 0.6423523472993438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,SVM,DT,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_logistic_regression,y_pred_svm, y_pred_mlp,y_pred_decision_tree,y_pred_extra_trees,]) # predictions of 5 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "sDwYNFgh0-TC",
        "outputId": "9cc4bbc2-661b-4386-f616-77f872b4e2bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.37      0.16      0.22       438\n",
            "      Negative       0.50      0.29      0.36       480\n",
            "      Positive       0.69      0.90      0.78      2257\n",
            "     not-Tamil       0.72      0.52      0.61       176\n",
            " unknown_state       0.48      0.33      0.39       611\n",
            "\n",
            "      accuracy                           0.64      3962\n",
            "     macro avg       0.55      0.44      0.47      3962\n",
            "  weighted avg       0.60      0.64      0.60      3962\n",
            "\n",
            "[[  70   43  274    5   46]\n",
            " [  30  137  264    7   42]\n",
            " [  48   58 2028   12  111]\n",
            " [   3    0   65   92   16]\n",
            " [  39   35  326   11  200]]\n",
            "Accuracy: 0.6378091872791519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LR,RF,DT,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_logistic_regression,y_pred_random_forest, y_pred_mlp,y_pred_decision_tree,y_pred_extra_trees,]) # predictions of 5 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "0g4wizLA1HiK",
        "outputId": "fcf4335c-4cf7-41cf-a6f8-9c04b71da473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 0 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.40      0.13      0.20       438\n",
            "      Negative       0.50      0.17      0.25       480\n",
            "      Positive       0.65      0.94      0.77      2257\n",
            "     not-Tamil       0.76      0.44      0.56       176\n",
            " unknown_state       0.56      0.28      0.37       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.58      0.39      0.43      3962\n",
            "  weighted avg       0.60      0.63      0.57      3962\n",
            "\n",
            "[[  57   21  327    2   31]\n",
            " [  16   81  345    6   32]\n",
            " [  35   42 2115    8   57]\n",
            " [   2    1   85   77   11]\n",
            " [  31   16  387    8  169]]\n",
            "Accuracy: 0.6307420494699647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM,RF,DT,MLP,EXT\n",
        "#So extra Trees and random forest gives same result ig? lets check\n",
        "'''y_pred_extra_trees 0.54\n",
        "y_pred_mlp            0.58\n",
        "y_pred_decision_tree  0.51\n",
        "y_pred_random_forest  0.53\n",
        "y_pred_svm            0.58\n",
        "y_pred_logistic_regression  0.59 '''\n",
        "predictions = np.array([y_pred_svm,y_pred_random_forest, y_pred_mlp,y_pred_decision_tree,y_pred_extra_trees,]) # predictions of 5 models majority voting\n",
        "print(predictions)\n",
        "reverse_mapping = {value: key for key, value in mapping.items()}\n",
        "final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "decoded_labels = [reverse_mapping[label] for label in final_pred]\n",
        "\n",
        "print(classification_report(dev['category'], decoded_labels))\n",
        "print(confusion_matrix(dev['category'], decoded_labels))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual1,decoded_labels ))"
      ],
      "metadata": {
        "id": "0hn8OWgt1QkX",
        "outputId": "4c418907-bc66-4ef0-ecd3-05b9e1953dab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [4 4 4 ... 4 4 4]\n",
            " [1 4 4 ... 4 1 4]\n",
            " [4 4 4 ... 4 4 4]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.36      0.12      0.18       438\n",
            "      Negative       0.51      0.19      0.28       480\n",
            "      Positive       0.65      0.93      0.77      2257\n",
            "     not-Tamil       0.76      0.46      0.57       176\n",
            " unknown_state       0.55      0.27      0.37       611\n",
            "\n",
            "      accuracy                           0.63      3962\n",
            "     macro avg       0.57      0.40      0.43      3962\n",
            "  weighted avg       0.59      0.63      0.57      3962\n",
            "\n",
            "[[  54   30  319    5   30]\n",
            " [  17   91  336    6   30]\n",
            " [  41   40 2102    8   66]\n",
            " [   3    1   82   81    9]\n",
            " [  34   18  385    7  167]]\n",
            "Accuracy: 0.6297324583543665\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}